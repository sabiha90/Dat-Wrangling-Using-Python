{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating a subset of the data\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import xml.etree.ElementTree as ET  # Use cElementTree or lxml if too slow\n",
    "\n",
    "OSM_FILE = \"/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin_texas.osm\"  # Replace this with your osm file\n",
    "SAMPLE_FILE = \"/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin.osm\"\n",
    "\n",
    "k = 10 # Parameter: take every k-th top level element\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tags.py\n",
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] +=1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon']+=1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars']+=1\n",
    "        else:\n",
    "            keys['other']+=1\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    return keys\n",
    "\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "\n",
    "process_map('/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#users.py\n",
    "\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "\n",
    "def get_user(element):\n",
    "    user = element.attrib['user']\n",
    "    return user\n",
    "\n",
    "\n",
    "def process_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.tag == \"node\":\n",
    "            users.add(get_user(element))\n",
    "        pass\n",
    "\n",
    "    return users\n",
    "\n",
    "\n",
    "def test():\n",
    "\n",
    "    users = process_map('/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin.osm')\n",
    "    pprint.pprint(users)\n",
    "    assert len(users) == 6\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mapparser.py\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_tags(filename):\n",
    "    counts = defaultdict(int)\n",
    "    for line in ET.iterparse(filename):\n",
    "        current = line[1].tag\n",
    "        counts[current] += 1\n",
    "    return counts\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin.osm')\n",
    "    pprint.pprint(tags)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#audit\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "zipcodes = set()\n",
    "phone_num = []\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\"]\n",
    "\n",
    "# UPDATE THIS VARIABLE\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"Pkwy\" : \"Parkway\",\n",
    "            \"Ln\" : \"Lane\",\n",
    "            \"CV\" : \"Cove\",\n",
    "            \"Cv\" : \"Cove\",\n",
    "            \"Hwy\" : \"Highway\",\n",
    "            \"Expy\" : \"Expressway\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"W.\": \"West\",\n",
    "            \"N.\": \"North\",\n",
    "            \"S.\": \"South\",\n",
    "            \"E\": \"East\",\n",
    "            \"Blvd.\" : \"Boulevard\",\n",
    "            \"Blvd\" : \"Boulevard\"}\n",
    "\n",
    "##Checking the different street types\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "    return street_types\n",
    " \n",
    "##Checking if the zipcode conforms to the total lenght of 5    \n",
    "def audit_zipcode(zipcodes, zipcode):\n",
    "    \n",
    "    if re.match(r'^\\d{5}$', zipcode):\n",
    "        zipcodes.add(zipcode)\n",
    "    if re.match(r'^\\d{5}\\:\\d{5}$', zipcode):\n",
    "        zips = zipcode.split(\":\")\n",
    "        zipcodes.add(zips[0])\n",
    "    \n",
    "    return zipcodes\n",
    "\n",
    "\n",
    "def audit_phone(phone_num, phone):\n",
    "    pattern = r'^\\(?([0-9]{3})\\)?[-.●]?([0-9]{3})[-.●]?([0-9]{4})$'\n",
    "    if re.match(r'^\\(?[+1]?([0-1]{1})\\)?[ -]?([0-9]{3})?[-.●  ]?([0-9]{3})[-.●  ]?([0-9]{4})$', phone):\n",
    "        phone_num.append(phone)\n",
    "    if re.match(r'^\\(?([0-9]{3})\\)?[-.●]?([0-9]{3})[-.●]?([0-9]{4})$', phone):\n",
    "        phone = \"+1 \" + phone\n",
    "        phone_num.append(phone)\n",
    "        return phone_num\n",
    "\n",
    "def is_phone_num(elem):\n",
    "    return 'phone' in elem.attrib['k'] \n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "def is_zip_code(elem):\n",
    "    return 'zip' in elem.attrib['k']\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    \n",
    "    street_types = defaultdict(set)\n",
    "    \n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "                if is_zip_code(tag):\n",
    "                    audit_zipcode(zipcodes, tag.attrib['v'])\n",
    "                if is_phone_num(tag):\n",
    "                    audit_phone(phone_num, tag.attrib['v'])\n",
    "                #print phone_num\n",
    "    return street_types, zipcodes, phone_num\n",
    "\n",
    "                \n",
    "    #return {'Street': street_types,'Zip':zipcodes, 'Phone numbers':phone_num}\n",
    "                    \n",
    "\n",
    "def update_name(name, mapping):\n",
    "    after = []\n",
    "    # Split name string to test each part of the name;\n",
    "    # Replacements may come anywhere in the name.\n",
    "    for part in name.split(\" \"):\n",
    "        # Check each part of the name against the keys in the correction dict\n",
    "        if part in mapping.keys():\n",
    "            # If exists in dict, overwrite that part of the name with the dict value for it.\n",
    "            part = mapping[part]\n",
    "        # Assemble each corrected piece of the name back together.\n",
    "        after.append(part)\n",
    "    # Return all pieces of the name as a string joined by a space.\n",
    "    return \" \".join(after)\n",
    "    return name\n",
    "\n",
    "def audit_test():\n",
    "    st_types,zips,ph = audit(OSMFILE)\n",
    "    \n",
    "    #assert len(st_types) == 3\n",
    "    #pprint.pprint(dict(st_types))\n",
    "    #print(zips)\n",
    "    #pprint.pprint(st_types) \n",
    "    updated_phones = update_phone(ph)\n",
    "    #print updated_phones\n",
    "    #print zips\n",
    "        \n",
    "    \n",
    "    for st_type, ways in st_types.iteritems():\n",
    "    \n",
    "        #print st_type,\n",
    "        print ways\n",
    "        \n",
    "        for name in ways:\n",
    "         \n",
    "                \n",
    "            update_name(name, mapping)\n",
    "            better_name = update_name(name, mapping)\n",
    "            #print better_name\n",
    "            #print name, \"=>\", better_name\n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    audit_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.py\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "import codecs\n",
    "import json\n",
    "import audit\n",
    "\n",
    "\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"Dr\" : \"Drive\",\n",
    "            \"Pkwy\" : \"Parkway\",\n",
    "            \"Ln\" : \"Lane\",\n",
    "            \"CV\" : \"Cove\",\n",
    "            \"Cv\" : \"Cove\",\n",
    "            \"Hwy\" : \"Highway\",\n",
    "            \"HWY\" : \"Highway\",\n",
    "            \"Expy\" : \"Expressway\",\n",
    "            \"Ave\": \"Avenue\",\n",
    "            \"Rd\": \"Road\",\n",
    "            \"W.\": \"West\",\n",
    "            \"N.\": \"North\",\n",
    "            \"S.\": \"South\",\n",
    "            \"E\": \"East\",\n",
    "            \"Blvd.\" : \"Boulevard\",\n",
    "            \"Blvd\" : \"Boulevard\"}\n",
    "\n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "ZIPCODE_TAGS = ['addr:postcode', 'tiger:zip_left', 'tiger:zip_left_1', 'tiger:zip_left_2',\n",
    "    'tiger:zip_left_3', 'tiger:zip_left_4', 'tiger:zip_right', 'tiger:zip_right_1',\n",
    "    'tiger:zip_right_2', 'tiger:zip_right_3', 'tiger:zip_right_4']\n",
    "phone_number_key = [\"contact:phone\",\"phone\"]\n",
    "IGNORED_TAGS = ['gnis:ST_num', 'text', 'tiger:Name', 'gnis:id', 'is_in',\n",
    "    'gnis:feature_type', 'lake:surface_area:acres', 'gnis:county_id', 'iata',\n",
    "    'stop', 'trees', 'icao', 'gnis:County', 'gnis:county_num', 'name:en', 'gnis:state_id',\n",
    "    'health_specialty:palliative_medicine', 'tiger:STATEFP', 'name:ru', 'name:uk'\n",
    "    'wikipedia:en', 'Hardware Store', 'isced', 'reg_ref', 'start_date',\n",
    "    'reg_name', 'al', 'isced:level', 'source:maxspeed', 'gnis_state_id',\n",
    "    'undefined', 'int_ref', 'source:ref:note', 'gnis:ST_alpha', 'gnis:feature_id',\n",
    "    'practice', 'lake:shore_length:miles', 'gnis:edited', 'gnis:freature_id',\n",
    "    'name:ar', 'cycleway:left', 'import_uuid', 'odbl:note', 'is_in:state',\n",
    "    'gnis:reviewed', 'name:backward', 'gnis:fcode', 'is_in:country_code',\n",
    "    'is_in:iso_3166_2', 'name:brand', 'name:pl', 'gnis:st_alpha']\n",
    "\n",
    "zipcodes = []\n",
    "phone_num = []\n",
    "phone_numbers = []\n",
    "node = {}\n",
    "address_info = {}\n",
    "nd_info = []\n",
    "\n",
    "\n",
    "def is_address(elem):\n",
    "    if elem.attrib['k'][:5] == \"addr:\":\n",
    "        return True\n",
    "\n",
    "def shape_element(element):\n",
    "    \n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        #pprint.pprint(element.attrib)\n",
    "        node[\"type\"] = element.tag\n",
    "        node[\"id\"] = element.attrib[\"id\"]\n",
    "        if \"visible\" in element.attrib.keys():\n",
    "            node[\"visible\"] = element.attrib[\"visible\"]\n",
    "        if \"lat\" in element.attrib.keys():\n",
    "            node[\"pos\"] = [float(element.attrib['lat']), float(element.attrib['lon'])]\n",
    "        node[\"created\"] = {\"version\": element.attrib['version'],\n",
    "                            \"changeset\": element.attrib['changeset'],\n",
    "                            \"timestamp\": element.attrib['timestamp'],\n",
    "                            \"uid\": element.attrib['uid'],\n",
    "                            \"user\": element.attrib['user']}\n",
    "        for tag in element.iter(\"tag\"):\n",
    "            p = problemchars.search(tag.attrib['k'])\n",
    "            ##If problematic characters, skip it\n",
    "            if p:\n",
    "                #print \"PROBLEM:\", p.group()\n",
    "                continue\n",
    "            #Cleaning and extracting the street names, housenumber and zipcodes\n",
    "            if tag.attrib['k'][:5] == \"addr:\":\n",
    "                if \":\" in tag.attrib['k'][5:]:\n",
    "                    continue\n",
    "                else:\n",
    "                    \n",
    "                    if tag.attrib['k'] == \"addr:street\":\n",
    "                        string = tag.attrib['v']\n",
    "                        groups = [group.strip() for group in string.split(';')]\n",
    "                        street_names = audit.update_name(groups[0],mapping)\n",
    "                        address_info['Street'] = street_names\n",
    "                    if tag.attrib['k'] == \"addr:housenumber\":\n",
    "                        address_info[\"housenumber\"] = tag.attrib['v']\n",
    "                        \n",
    "            \n",
    "                        #print address_info\n",
    "            if tag.attrib['k'] in ZIPCODE_TAGS:\n",
    "                clean_zipcode(zipcodes, tag.attrib['v'])\n",
    "                for zips in zipcodes:\n",
    "                    address_info['zip'] = zips\n",
    "                #print address_info\n",
    "            #Adding phone numbers\n",
    "            if tag.attrib['k'] in phone_number_key:\n",
    "                phone = clean_phonenumber(phone_num,tag.attrib['v'])\n",
    "                for num in phone:\n",
    "                    res = re.sub(\"[^\\+.\\d]\",\" \",num)\n",
    "                node['Phone'] = res\n",
    "            \n",
    "            if tag.attrib['k'] in IGNORED_TAGS:\n",
    "                continue\n",
    "           \n",
    "        if address_info != {}:\n",
    "            node['address'] = address_info\n",
    "    \n",
    "    return node\n",
    "\n",
    "#Cleaning the zipcodes\n",
    "def clean_zipcode(zipcodes, zipcode):\n",
    "    if re.match(r'^\\d{5}$', zipcode):\n",
    "        zipcodes.append(zipcode)\n",
    "    if re.match(r'^\\d{5}\\:\\d{5}$', zipcode):\n",
    "        zips = zipcode.split(\":\")\n",
    "        zipcodes.append(zips[0])\n",
    "    return zipcodes\n",
    "\n",
    "##Cleaning the phone numbers\n",
    "def clean_phonenumber(phone_num, phones):\n",
    "    if re.match(r'^[+1]?([0-1]{1})+[ -]?\\(?([0-9]{3})\\)?[-.●  ]?([0-9]{3})[-.●  ]?([0-9]{4})$', phones):\n",
    "        phone_num.append(phones)\n",
    "    #print phone_num\n",
    "    if re.match(r'^\\+?([0-1]{0})?[ -]?\\(?([0-9]{3})\\)?[-.●  ]?([0-9]{3})[-.●  ]?([0-9]{4})$',phones):\n",
    "        phones = '+1-' + phones\n",
    "    phone_num.append(phones)\n",
    "    return phone_num\n",
    "    \n",
    "##Writing the data to a json file   \n",
    "def process_map(file_in, pretty = False):\n",
    "    # You do not need to change this file\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for _, element in ET.iterparse(file_in):\n",
    "            #print element\n",
    "            el = shape_element(element)\n",
    "            #print el\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "\n",
    "def test():\n",
    "    # NOTE: if you are running this code on your computer, with a larger dataset, \n",
    "    # call the process_map procedure with pretty=False. The pretty=True option adds \n",
    "    # additional spaces to the output, making it significantly larger.\n",
    "    data = process_map('/Users/sabihabarlaskar/Desktop/udacity-nanodegree/P3 Data wrangling/project/austin.osm', True)\n",
    "    \n",
    "    #pprint.pprint(data)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
